{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Transfer Learning Model Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details about implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will provide a layout to implement a transfer learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 06:02:27.785234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738044147.966431   20444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738044148.011604   20444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    GlobalAveragePooling2D,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import image_dataset_from_directory, load_img, img_to_array\n",
    "from tensorflow.keras.applications import (\n",
    "    InceptionV3,\n",
    "    EfficientNetV2B3,\n",
    "    Xception,\n",
    "    MobileNetV2,\n",
    "    MobileNetV3Large,\n",
    ")\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "MODEL_NAME = \"tl_model_template\"\n",
    "\n",
    "NUM_CLASSES = 38\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = image_dataset_from_directory()\n",
    "validation_set = image_dataset_from_directory()\n",
    "test_set = image_dataset_from_directory()\n",
    "normalized_training_set = training_set\n",
    "normalized_validation_set = validation_set\n",
    "normalized_test_set = test_set\n",
    "augmented_training_set = normalized_training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load InceptionV3 model pre-trained on ImageNet without the top (classification) layer\n",
    "base_model = InceptionV3(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    ")\n",
    "\n",
    "# Freeze the base model (don't update weights during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# # fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:  # Freeze all layers except the last 20\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of the base model\n",
    "x = GlobalAveragePooling2D()(base_model.output)  # Reduce spatial dimensions\n",
    "x = BatchNormalization()(x)  # Normalize features to improve training stability\n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Dropout(0.4)(x)  # Dropout for regularization\n",
    "x = Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))(\n",
    "    x\n",
    ")  # Add a smaller dense layer for hierarchical learning\n",
    "x = Dropout(0.3)(x)  # Another dropout layer with lower rate\n",
    "predictions = Dense(NUM_CLASSES, activation=\"softmax\")(x)  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the complete model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Callbacks for Early Stopping and Model Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=f\"../models/checkpoints/{MODEL_NAME}_best_weights_{now.strftime(\"%Y_%m_%d_%I_%M_%S_%p\")}.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping, lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 69\n",
      "validation_steps: 18\n"
     ]
    }
   ],
   "source": [
    "# Get the number of samples in the training and validation datasets\n",
    "train_samples = len(training_set) \n",
    "validation_samples = len(\n",
    "    validation_set\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch and validation steps\n",
    "steps_per_epoch = (train_samples + (BATCH_SIZE - 1)) // BATCH_SIZE\n",
    "validation_steps = (validation_samples + (BATCH_SIZE - 1)) // BATCH_SIZE\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)\n",
    "\n",
    "# Compute class weights to balance the dataset\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(validation_set.class_names),\n",
    "    y=validation_set.class_names,\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738044324.744625   20632 service.cc:148] XLA service 0xe5f2d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738044324.745422   20632 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "I0000 00:00:1738044327.201833   20632 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/69\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:55\u001b[0m 18s/step - accuracy: 0.0312 - loss: 7.5459"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1738044337.339537   20632 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.0543 - loss: 7.3627\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21354, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 253ms/step - accuracy: 0.0547 - loss: 7.3592 - val_accuracy: 0.2135 - val_loss: 6.5993 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1583 - loss: 6.4739\n",
      "Epoch 2: val_accuracy improved from 0.21354 to 0.39236, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 173ms/step - accuracy: 0.1587 - loss: 6.4718 - val_accuracy: 0.3924 - val_loss: 6.0680 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2795 - loss: 5.9267\n",
      "Epoch 3: val_accuracy improved from 0.39236 to 0.49479, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 187ms/step - accuracy: 0.2800 - loss: 5.9249 - val_accuracy: 0.4948 - val_loss: 5.5576 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.3765 - loss: 5.4792\n",
      "Epoch 4: val_accuracy improved from 0.49479 to 0.51562, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - accuracy: 0.3766 - loss: 5.4786 - val_accuracy: 0.5156 - val_loss: 5.1336 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.4139 - loss: 5.2073\n",
      "Epoch 5: val_accuracy improved from 0.51562 to 0.58681, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 180ms/step - accuracy: 0.4142 - loss: 5.2060 - val_accuracy: 0.5868 - val_loss: 4.7570 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4880 - loss: 4.8701\n",
      "Epoch 6: val_accuracy improved from 0.58681 to 0.63368, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 183ms/step - accuracy: 0.4880 - loss: 4.8696 - val_accuracy: 0.6337 - val_loss: 4.4703 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5202 - loss: 4.6137\n",
      "Epoch 7: val_accuracy improved from 0.63368 to 0.65278, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.5203 - loss: 4.6132 - val_accuracy: 0.6528 - val_loss: 4.2364 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5262 - loss: 4.4673\n",
      "Epoch 8: val_accuracy did not improve from 0.65278\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.5262 - loss: 4.4672 - val_accuracy: 0.6493 - val_loss: 4.0672 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5569 - loss: 4.3330\n",
      "Epoch 9: val_accuracy improved from 0.65278 to 0.68924, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 192ms/step - accuracy: 0.5570 - loss: 4.3322 - val_accuracy: 0.6892 - val_loss: 3.8857 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5952 - loss: 4.0862\n",
      "Epoch 10: val_accuracy improved from 0.68924 to 0.70833, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 193ms/step - accuracy: 0.5953 - loss: 4.0857 - val_accuracy: 0.7083 - val_loss: 3.7283 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5992 - loss: 3.9910\n",
      "Epoch 11: val_accuracy improved from 0.70833 to 0.71354, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 185ms/step - accuracy: 0.5993 - loss: 3.9902 - val_accuracy: 0.7135 - val_loss: 3.5890 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6079 - loss: 3.8096\n",
      "Epoch 12: val_accuracy improved from 0.71354 to 0.73958, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.6081 - loss: 3.8094 - val_accuracy: 0.7396 - val_loss: 3.4604 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.6297 - loss: 3.7278\n",
      "Epoch 13: val_accuracy improved from 0.73958 to 0.75868, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 184ms/step - accuracy: 0.6299 - loss: 3.7269 - val_accuracy: 0.7587 - val_loss: 3.3170 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6391 - loss: 3.5846\n",
      "Epoch 14: val_accuracy did not improve from 0.75868\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - accuracy: 0.6391 - loss: 3.5842 - val_accuracy: 0.7135 - val_loss: 3.3185 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6193 - loss: 3.5367\n",
      "Epoch 15: val_accuracy did not improve from 0.75868\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 178ms/step - accuracy: 0.6197 - loss: 3.5360 - val_accuracy: 0.7517 - val_loss: 3.1827 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6670 - loss: 3.4095\n",
      "Epoch 16: val_accuracy did not improve from 0.75868\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 173ms/step - accuracy: 0.6670 - loss: 3.4090 - val_accuracy: 0.7448 - val_loss: 3.0985 - learning_rate: 1.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.6696 - loss: 3.2903\n",
      "Epoch 17: val_accuracy improved from 0.75868 to 0.76389, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 174ms/step - accuracy: 0.6697 - loss: 3.2897 - val_accuracy: 0.7639 - val_loss: 2.9551 - learning_rate: 1.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.6643 - loss: 3.1961\n",
      "Epoch 18: val_accuracy improved from 0.76389 to 0.76562, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 181ms/step - accuracy: 0.6644 - loss: 3.1956 - val_accuracy: 0.7656 - val_loss: 2.8914 - learning_rate: 1.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7010 - loss: 3.0934\n",
      "Epoch 19: val_accuracy did not improve from 0.76562\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.7010 - loss: 3.0930 - val_accuracy: 0.7622 - val_loss: 2.8400 - learning_rate: 1.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.6841 - loss: 3.0793\n",
      "Epoch 20: val_accuracy did not improve from 0.76562\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - accuracy: 0.6842 - loss: 3.0786 - val_accuracy: 0.7483 - val_loss: 2.7986 - learning_rate: 1.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6994 - loss: 2.9388\n",
      "Epoch 21: val_accuracy did not improve from 0.76562\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 176ms/step - accuracy: 0.6994 - loss: 2.9390 - val_accuracy: 0.7569 - val_loss: 2.6946 - learning_rate: 1.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6885 - loss: 2.8996\n",
      "Epoch 22: val_accuracy improved from 0.76562 to 0.78125, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 184ms/step - accuracy: 0.6885 - loss: 2.8998 - val_accuracy: 0.7812 - val_loss: 2.5868 - learning_rate: 1.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7050 - loss: 2.7904\n",
      "Epoch 23: val_accuracy did not improve from 0.78125\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - accuracy: 0.7050 - loss: 2.7901 - val_accuracy: 0.7691 - val_loss: 2.5593 - learning_rate: 1.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7155 - loss: 2.7453\n",
      "Epoch 24: val_accuracy did not improve from 0.78125\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 175ms/step - accuracy: 0.7155 - loss: 2.7449 - val_accuracy: 0.7726 - val_loss: 2.4672 - learning_rate: 1.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7289 - loss: 2.6686\n",
      "Epoch 25: val_accuracy did not improve from 0.78125\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - accuracy: 0.7286 - loss: 2.6691 - val_accuracy: 0.7812 - val_loss: 2.4312 - learning_rate: 1.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7077 - loss: 2.6362\n",
      "Epoch 26: val_accuracy improved from 0.78125 to 0.81250, saving model to checkpoints/new_model_best_weights.keras\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 189ms/step - accuracy: 0.7078 - loss: 2.6360 - val_accuracy: 0.8125 - val_loss: 2.3406 - learning_rate: 1.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7403 - loss: 2.5048\n",
      "Epoch 27: val_accuracy did not improve from 0.81250\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - accuracy: 0.7403 - loss: 2.5047 - val_accuracy: 0.7934 - val_loss: 2.3101 - learning_rate: 1.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7159 - loss: 2.5177\n",
      "Epoch 28: val_accuracy did not improve from 0.81250\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - accuracy: 0.7158 - loss: 2.5177 - val_accuracy: 0.7951 - val_loss: 2.2443 - learning_rate: 1.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7504 - loss: 2.3741\n",
      "Epoch 29: val_accuracy did not improve from 0.81250\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 176ms/step - accuracy: 0.7501 - loss: 2.3749 - val_accuracy: 0.7917 - val_loss: 2.2040 - learning_rate: 1.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7675 - loss: 2.3031\n",
      "Epoch 30: val_accuracy did not improve from 0.81250\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 174ms/step - accuracy: 0.7674 - loss: 2.3031 - val_accuracy: 0.8073 - val_loss: 2.1114 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "training_history = model.fit(\n",
    "    augmented_training_set,\n",
    "    epochs=30,\n",
    "    validation_data=normalized_validation_set,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 179ms/step - accuracy: 0.8342 - loss: 2.0235\n",
      "Training accuracy: 0.8354790806770325\n"
     ]
    }
   ],
   "source": [
    "# Training set Accuracy\n",
    "train_loss, train_acc = model.evaluate(augmented_training_set)\n",
    "print(\"Training accuracy:\", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - accuracy: 0.8001 - loss: 2.1428\n",
      "Validation accuracy: 0.7982586026191711\n"
     ]
    }
   ],
   "source": [
    "# Validation set Accuracy\n",
    "val_loss, val_acc = model.evaluate(normalized_validation_set)\n",
    "print(\"Validation accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'../models/{MODEL_NAME}_{now.strftime(\"%Y_%m_%d_%I_%M_%S_%p\")}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history\n",
    "with open(\n",
    "    f\"training_histories/training_history_{MODEL_NAME}_{now.strftime(\"%Y_%m_%d_%I_%M_%S_%p\")}.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(training_history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_set], axis=0)\n",
    "\n",
    "if y_true.ndim > 1:  # If it's one-hot encoded\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "print(f\"y_true shape: {y_true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels using the trained model\n",
    "y_pred = model.predict(normalized_test_set)\n",
    "\n",
    "if y_pred.ndim > 1:  # If it's one-hot encoded or probabilities\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(f\"y_pred shape: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the classification report\n",
    "report = classification_report(y_true, y_pred, target_names=test_set.class_names)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_heatmap(model, test_set, class_names):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix as a heatmap for a given model and validation dataset.\n",
    "    Uses human-readable class names for display.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained model.\n",
    "        test_set: Test dataset (normalized).\n",
    "        class_names: List of class names.\n",
    "    \"\"\"\n",
    "    # Get true labels and predictions\n",
    "    true_labels = np.concatenate([y for x, y in test_set], axis=0)\n",
    "    predicted_probs = model.predict(test_set)\n",
    "\n",
    "    # If true_labels are one-hot encoded, convert them to class indices\n",
    "    if true_labels.ndim > 1:  # Check if one-hot encoded\n",
    "        true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "    # Convert predicted probabilities to class indices\n",
    "    predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Plot confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        annot_kws={\"size\": 10},\n",
    "        cmap=\"magma\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Predicted Class\", fontsize=20)\n",
    "    plt.ylabel(\"Actual Class\", fontsize=20)\n",
    "    plt.title(\"Plant Disease Prediction Confusion Matrix\", fontsize=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_heatmap(model, normalized_test_set, test_set.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train | Vaild Accuracy & Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots training and validation accuracy and loss graphs.\n",
    "\n",
    "    Parameters:\n",
    "        history: The History object returned by model.fit().\n",
    "    \"\"\"\n",
    "    # Extract metrics\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs, val_acc, label=\"Validation Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graphs\n",
    "plot_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".AgroDiagnoseAI_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
